'''
Long Short-Term Memory networks (LSTMs) are a type of Recurrent Neural Network (RNN) and are typically used in the context
of supervised learning, particularly for sequence prediction problems like time series forecasting, natural language processing,
and more. In these applications, you usually have labeled data where the sequence input is associated with a corresponding output.

That being said, LSTMs can also be used in unsupervised learning scenarios. For example, you can use LSTMs in autoencoders for
sequence-to-sequence reconstruction, anomaly detection in time series data, or learning embeddings for sequences without explicit labels.
'''